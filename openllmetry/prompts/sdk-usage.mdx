---
title: "Fetching Prompts"
description: "Use your managed prompts with the Traceloop SDKs"
---

### Using your prompt

The SDK fetches your prompts from Traceloop servers. Changes made to a prompt are available in the SDK during runtime.
The SDK polls the Traceloop servers for changes every every poll interval.

The default poll interval is 60 seconds but can be configured with the `TRACELOOP_SYNC_POLL_INTERVAL` environment variable, or the initialization function.
When in the `Development` environment, the poll interval is determined by the `TRACELOOP_SYNC_DEV_POLL_INTERVAL` environment variable or appropriate initialization argument, and defaults to 5 seconds.

To disable polling all together, set the `TRACELOOP_SYNC_ENABLED` environment variable to false (its enabled by default).

Make sure you've configured the SDK with the right environment and API Key. See the [SDK documentation](/openllmetry/configuration#api-key) for more information.

<Tip>
  The SDK uses smart caching mechanisms to proide zero latency for fetching prompts.
</Tip>

## Get Prompt API

Let's say you've created a prompt with a key `joke_generator` in the UI and set ot to:

```
Tell me a joke about OpenTelemetry as a {{persona}}
```

Then, you can retrieve it with in your code using `get_prompt`:

```python
from traceloop.sdk.prompts import get_prompt

prompt_args = get_prompt("joke_generator", persona="pirate")
completion = openai.ChatCompletion.create(**prompt_args)
```

<Tip>
  The returned variable `prompt_args` is compatible with the API used by the
  foundation models SDKs (OpenAI, Anthropic, etc.) which means you should directly
  plug in the response to the appropriate API call.
</Tip>
