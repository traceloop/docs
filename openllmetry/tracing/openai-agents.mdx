---

title: "OpenAI Agents"
description: "Automatic tracing for the openai-agents package"
---

OpenLLMetry automatically instruments the official `openai-agents` package, allowing you to monitor agent workflows without any additional code changes.

<CodeGroup>

```python Python
from dotenv import load_dotenv
from traceloop.sdk import Traceloop
from agents import Agent, Runner, function_tool

load_dotenv()

# Initialise tracing once in your application
Traceloop.init(
    app_name="minimal_openai_agents_example",
    # Disable batching so you can see traces immediately during development
    disable_batch=True,
)

@function_tool
def multiply_numbers(a: float, b: float) -> float:
    """Simple multiplication calculator tool."""
    return a * b

simple_agent = Agent(
    model="gpt-4o-mini",
    name="Simple Agent",
    instructions="You are a helpful assistant. Answer questions clearly and concisely.",
    tools=[multiply_numbers],
)

result = Runner.run_sync(simple_agent, "Calculate 150 × 2 then multiply by 3")
print(result.final_output)
```

</CodeGroup>

> **Tip**
> No decorators or special wrappers are needed – every call made by the agent, its tools and the underlying OpenAI models is captured automatically.

The resulting trace will show a clear hierarchy of spans for the agent run, tool invocations and model calls:

<Frame>
  <img className="block dark:hidden" src="/img/trace-light.png" />
  <img className="hidden dark:block" src="/img/trace-dark.png" />
</Frame>

That's it!  For additional configuration options (such as exporting to a different backend or tweaking batching behaviour) see the [Python getting-started guide](/openllmetry/getting-started-python).
