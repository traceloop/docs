---
title: "Quick Start"
---

<Frame>
  <img src="/img/prompt_configuration.png" />
</Frame>

You can use Traceloop to manage your prompts and model configurations.
That way you can easily experiment with different prompts, and rollout changes gradually and safely.

<Note>
  Make sure you've created an API key and set it as an environment variable
  `TRACELOOP_API_KEY` before you start. Check out the SDK's [getting started
  guide](/openllmetry/getting-started-python) for more information.
</Note>

<Steps>
<Step title="Create a new prompt">

Click **New Prompt** to create a new prompt. Give it a name, which will be used to retrieve it in your code later.

</Step>

<Step title="Define it in the Prompt Registry">
Set the system and/or user prompt. You can use variables in your prompt by
following the [Jinja format](https://jinja.palletsprojects.com/en/3.1.x/templates/) of `{{ variable_name }}`. 
The values of these variables will be passed in when you retrieve the prompt in your code.

For more information see the [Registry Documentation](/prompts/registry).

<Tip>
  This screen is also a prompt playground. Give the prompt a try by clicking
  **Test** at the bottom.
</Tip>

</Step>

<Step title="Deploy the prompt to your developement environement">
  Click **Deploy to Dev** to deploy the prompt to your development environment.
</Step>

<Step title="Use the prompt in your code">

If you haven't done so, make sure to [generate an API key](https://app.traceloop.com/settings/api-keys) and
set it as an environment variable `TRACELOOP_API_KEY`.

Make sure to initialize the SDK. On Typescript/Javascript, you should also wait for the initialization to complete.

<CodeGroup>

```python Python
from traceloop.sdk import Traceloop

Traceloop.init()
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

traceloop.initialize();
await traceloop.waitForInitialization();
```

</CodeGroup>

Retrieve your prompt by using the `get_prompt` function.
For example, if you've created a prompt with the key `joke_generator` and a single variable `persona`:

<CodeGroup>

```python Python
from openai import OpenAI
from traceloop.sdk.prompts import get_prompt

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

prompt_args = get_prompt(key="joke_generator", variables={"persona": "pirate"})
completion = client.chat.completions.create(**prompt_args)
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

const prompt = traceloop.getPrompt("joke_generator", { persona: "pirate" });
const chatCompletion = await openai.chat.completions.create(prompt);
```

```go Go
import "github.com/sashabaranov/go-openai"

func call_llm() {
  // traceloop is the object you got when you initialized the SDK
  request, err := traceloop.GetOpenAIChatCompletionRequest("joke_generator", map[string]interface{}{ "persona": "pirate" })
  if err != nil {
    fmt.Printf("GetOpenAIChatCompletionRequest error: %v\n", err)
    return
  }
  client := openai.NewClient(os.Getenv("OPENAI_API_KEY"))
    resp, err := client.CreateChatCompletion(
      context.Background(),
      *request,
    )
}
```

</CodeGroup>

<Note>
  The returned variable `prompt_args` is compatible with the API used by the
  foundation models SDKs (OpenAI, Anthropic, etc.) which means you can directly
  plug in the response to the appropriate API call.
</Note>

For more information see the [SDK Usage Documentation](/prompts/sdk-usage).

</Step>
</Steps>
