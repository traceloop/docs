---
title: "SDK usage"
description: "Access your managed datasets with the Traceloop SDK"
---

## SDK Initialization

First, initialize the Traceloop SDK with dataset sync enabled:

<CodeGroup>

```python Python
from traceloop.sdk import Traceloop

# Initialize with dataset sync enabled
client = Traceloop.init()
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

// Initialize with comprehensive configuration
traceloop.initialize({
  appName: "your-app-name",
  apiKey: process.env.TRACELOOP_API_KEY,
  disableBatch: true,
  traceloopSyncEnabled: true,
});

// Wait for initialization to complete
await traceloop.waitForInitialization();

// Get the client instance for dataset operations
const client = traceloop.getClient();
```

</CodeGroup>

<Note>
  Make sure you've created an API key and set it as an environment variable
  `TRACELOOP_API_KEY` before you start. Check out the SDK's [getting started
  guide](/openllmetry/getting-started-python) for more information.
</Note>

The SDK fetches your datasets from Traceloop servers. Changes made to a draft dataset version are immediately available in the UI.

## Dataset CRUD Operations

### Create a dataset

<CodeGroup>

```python Python
import pandas as pd
from traceloop.sdk import Traceloop

client = Traceloop.init()

# Create dataset from CSV file
dataset = client.datasets.from_csv(
    file_path="path/to/your/data.csv",
    slug="my-dataset-slug",
    name="My Dataset Name",
    description="Description of the dataset contents"
)

print(f"Created dataset: {dataset.slug}")
```

```js Typescript / Javascript

// Create a new dataset
const dataset = await client.datasets.create({
  name: `Medical Qustions}`,
  slug: `medical-questions`,
  description: "Dataset with patients medical questions"
});

console.log(`Created dataset: ${dataset.name} (ID: ${dataset.id})`);
```

</CodeGroup>

### Importing from CSV

<CodeGroup>

```python Python
# Python CSV import example above
```

```js Typescript / Javascript
// Import data from CSV string
const csvData = `user_id,prompt,response,model,satisfaction_score
user_001,"What is React?","React is a JavaScript library...","gpt-3.5-turbo",4
user_002,"Explain Docker","Docker is a containerization platform...","gpt-3.5-turbo",5`;

await dataset.fromCSV(csvData, { hasHeader: true });
console.log("Imported data from CSV");
```

</CodeGroup>

### From DataFrames

<CodeGroup>

```python Python
import pandas as pd
from traceloop.sdk import Traceloop

client = Traceloop.init()

# Create sample DataFrame
data = {
    "user_input": ["How do I reset my password?", "What's your refund policy?"],
    "ai_response": ["Click 'Forgot Password' on the login page.", "We offer 30-day returns."],
    "category": ["authentication", "billing"],
    "resolved": [True, True]
}
df = pd.DataFrame(data)

# Create dataset from DataFrame
dataset = client.datasets.from_dataframe(
    df=df,
    slug="support-interactions",
    name="Customer Support Dataset",
    description="Customer queries and AI responses"
)
```

</CodeGroup>

## Managing Dataset Structure

### Adding Columns

<CodeGroup>

```python Python
from traceloop.sdk.dataset import ColumnType

# Add a new column to your dataset
new_column = dataset.add_column(
    slug="confidence_score",
    name="Confidence Score", 
    col_type=ColumnType.NUMBER
)
```

```js Typescript / Javascript
// Define schema by adding multiple columns
const columnsToAdd = [
  {
    name: "user_id",
    type: "string" as const,
    required: true,
    description: "Unique identifier for the user"
  },
  {
    name: "prompt", 
    type: "string" as const,
    required: true,
    description: "The user's input prompt"
  },
  {
    name: "response",
    type: "string" as const,
    required: true,
    description: "The AI model's response"
  },
  {
    name: "tokens_used",
    type: "number" as const,
    required: false,
    description: "Total tokens consumed"
  },
  {
    name: "satisfaction_score",
    type: "number" as const,
    required: false,
    description: "User satisfaction rating (1-5)"
  }
];

await dataset.addColumn(columnsToAdd);
console.log("Schema defined with multiple columns");
```

</CodeGroup>

### Updating Columns

<CodeGroup>

```python Python
# Update column properties
column.update(
    name="Updated Column Name",
    type=ColumnType.STRING
)
```

</CodeGroup>

### Deleting Columns

<CodeGroup>

```python Python
# Delete a column
column.delete()
```

</CodeGroup>

## Managing Dataset Data

### Adding Rows

<CodeGroup>

```python Python
# Add new rows to your dataset
row_data = {
    "user_input": "New customer question",
    "ai_response": "Generated response",
    "category": "general",
    "resolved": True
}

dataset.add_rows([row_data])
```

```js Typescript / Javascript
// Add individual rows to dataset
const interaction = {
  user_id: "user_001",
  prompt: "Explain machine learning in simple terms",
  response: "Machine learning is a subset of AI that enables computers to learn...",
  model: "gpt-3.5-turbo",
  tokens_used: 150,
  response_time_ms: 1200,
  satisfaction_score: 4,
  timestamp: new Date().toISOString()
};

await dataset.addRow(interaction);
console.log("Added interaction record");
```

</CodeGroup>

### Updating Rows  

<CodeGroup>

```python Python
# Update existing row data
if dataset.rows:
    row = dataset.rows[0]  # Get first row
    
    updates = {
        "ai_response": "Updated response text",
        "resolved": True
    }
    
    row.update(updates)
```

</CodeGroup>

### Deleting Rows

<CodeGroup>

```python Python
# Delete a row
if dataset.rows:
    row = dataset.rows[0]
    row.delete()
```

</CodeGroup>

## Publishing and Versioning

### Publishing Datasets

<CodeGroup>

```python Python
# Publish the current dataset state as a new version
published_version = dataset.publish()
print(f"Published version: {published_version}")
```

</CodeGroup>

### Retrieving Specific Versions

<CodeGroup>

```python Python
# Get dataset by slug (latest version)
dataset = client.datasets.get_by_slug("my-dataset-slug")

# Get specific version as CSV
dataset_csv = client.datasets.get_version_csv(
    slug="my-dataset-slug", 
    version="1.2.0"
)
```

```js Typescript / Javascript
// Get dataset by slug
const retrievedDataset = await client.datasets.get("my-dataset-slug");
console.log(`Retrieved dataset: ${retrievedDataset.name}`);

// Get dataset information and rows
const rows = await dataset.getRows(); // Get all rows
const columns = await dataset.getColumns(); // Get all columns
console.log(`Total rows: ${rows.length}, Total columns: ${columns.length}`);

// List all datasets
const datasetsList = await client.datasets.list();
console.log(`Found ${datasetsList.total} total datasets`);
```

</CodeGroup>

### Data Analysis

<CodeGroup>

```python Python
# Analyze dataset contents
for row in dataset:
    print(f"User: {row['user_input']}")
    print(f"Response: {row['ai_response']}")
```

```js Typescript / Javascript
// Analyze collected data
const analysisRows = rows.slice(0, 10); // Get first 10 rows

// Calculate average satisfaction score
const satisfactionScores = analysisRows
  .map(row => row.data.satisfaction_score as number)
  .filter(score => score != null);

if (satisfactionScores.length > 0) {
  const avgSatisfaction = satisfactionScores.reduce((a, b) => a + b, 0) / satisfactionScores.length;
  console.log(`Average satisfaction score: ${avgSatisfaction.toFixed(2)}/5`);
}

// Calculate average response time
const responseTimes = analysisRows
  .map(row => row.data.response_time_ms as number)
  .filter(time => time != null);

if (responseTimes.length > 0) {
  const avgResponseTime = responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length;
  console.log(`Average response time: ${avgResponseTime.toFixed(0)}ms`);
}

// Show sample interactions
console.log("Sample interactions:");
analysisRows.slice(0, 3).forEach((row, index) => {
  console.log(`${index + 1}. User: "${row.data.prompt}"`);
  console.log(`   Response: "${String(row.data.response).substring(0, 80)}..."`);
  console.log(`   Satisfaction: ${row.data.satisfaction_score}/5`);
});
```

</CodeGroup>

## Get Dataset API

Let's say you've created a dataset with a key `evaluation_scenarios` containing test cases for your AI application:

| user_input | expected_tone | expected_length |
|------------|---------------|-----------------|
| "Help me write an email" | professional | medium |  
| "Create a fun story" | casual | long |
| "Summarize this document" | neutral | short |

Then, you can retrieve it in your code using `get_dataset`:

<CodeGroup>

```python Python
from traceloop.sdk.datasets import get_dataset

# Get the latest published version
dataset = get_dataset(key="evaluation_scenarios")

# Get a specific version
dataset = get_dataset(key="evaluation_scenarios", version="1.2.0")

# Iterate through all rows
for row in dataset:
    user_input = row["user_input"]  
    expected_tone = row["expected_tone"]
    expected_length = row["expected_length"]
    
    # Use the data in your tests
    result = generate_response(user_input)
    assert validate_tone(result, expected_tone)
    assert validate_length(result, expected_length)
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

// Get the latest published version
const dataset = traceloop.getDataset("evaluation_scenarios");

// Get a specific version  
const dataset = traceloop.getDataset("evaluation_scenarios", "1.2.0");

// Iterate through all rows
for (const row of dataset) {
    const userInput = row.user_input;
    const expectedTone = row.expected_tone;
    const expectedLength = row.expected_length;
    
    // Use the data in your tests
    const result = await generateResponse(userInput);
    console.assert(validateTone(result, expectedTone));
    console.assert(validateLength(result, expectedLength));
}
```

```go Go
import "github.com/traceloop/go-sdk/datasets"

func runTests() {
    // Get the latest published version
    dataset, err := datasets.GetDataset("evaluation_scenarios", "")
    if err != nil {
        log.Printf("GetDataset error: %v\n", err)
        return
    }
    
    // Get a specific version
    dataset, err = datasets.GetDataset("evaluation_scenarios", "1.2.0")
    if err != nil {
        log.Printf("GetDataset error: %v\n", err)
        return
    }
    
    // Iterate through all rows
    for _, row := range dataset {
        userInput := row["user_input"].(string)
        expectedTone := row["expected_tone"].(string) 
        expectedLength := row["expected_length"].(string)
        
        // Use the data in your tests
        result := generateResponse(userInput)
        assert.True(t, validateTone(result, expectedTone))
        assert.True(t, validateLength(result, expectedLength))
    }
}
```

</CodeGroup>

<Tip>
  Each row in the dataset is returned as a dictionary/object where column names
  are the keys. This makes it easy to access your structured test data.
</Tip>

## Dataset Versioning

When working with datasets, you can specify which version to use:

<CodeGroup>

```python Python
# Always get the latest published version (recommended for development)
dataset = get_dataset("my_dataset")

# Get a specific version (recommended for production/CI)
dataset = get_dataset("my_dataset", version="2.1.0")

# Get version info
dataset_info = get_dataset_info("my_dataset")
print(f"Latest version: {dataset_info.latest_version}")
print(f"Available versions: {dataset_info.versions}")
```

```js Typescript / Javascript
// Always get the latest published version (recommended for development)
const dataset = traceloop.getDataset("my_dataset");

// Get a specific version (recommended for production/CI)
const dataset = traceloop.getDataset("my_dataset", "2.1.0");

// Get version info
const datasetInfo = traceloop.getDatasetInfo("my_dataset");
console.log(`Latest version: ${datasetInfo.latestVersion}`);
console.log(`Available versions: ${datasetInfo.versions}`);
```

</CodeGroup>

## Common Usage Patterns

### Automated Testing

Use datasets to create comprehensive test suites:

<CodeGroup>

```python Python  
import pytest
from traceloop.sdk.datasets import get_dataset

class TestAIApplication:
    @pytest.fixture
    def test_cases(self):
        return get_dataset("ai_app_test_suite", version="1.0.0")
    
    def test_response_quality(self, test_cases):
        for case in test_cases:
            input_text = case["input"]
            expected_output = case["expected_output"]
            
            result = your_ai_function(input_text)
            
            # Add your validation logic
            similarity_score = calculate_similarity(result, expected_output)
            assert similarity_score > 0.8, f"Low similarity for input: {input_text}"
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

describe("AI Application Tests", () => {
    let testCases;
    
    beforeAll(async () => {
        testCases = traceloop.getDataset("ai_app_test_suite", "1.0.0");
    });
    
    test("response quality", async () => {
        for (const testCase of testCases) {
            const inputText = testCase.input;
            const expectedOutput = testCase.expected_output;
            
            const result = await yourAiFunction(inputText);
            
            // Add your validation logic
            const similarityScore = calculateSimilarity(result, expectedOutput);
            expect(similarityScore).toBeGreaterThan(0.8);
        }
    });
});
```

</CodeGroup>

### Batch Processing

Process entire datasets for bulk evaluation:

<CodeGroup>

```python Python
from traceloop.sdk.datasets import get_dataset
import concurrent.futures

def evaluate_dataset(dataset_key, version=None):
    dataset = get_dataset(dataset_key, version)
    results = []
    
    # Process in parallel for better performance
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        
        for row in dataset:
            future = executor.submit(process_single_case, row)
            futures.append(future)
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            results.append(result)
    
    return results

def process_single_case(row):
    # Your processing logic here
    input_data = row["input"]
    result = your_ai_function(input_data)
    
    return {
        "input": input_data,
        "output": result,
        "expected": row.get("expected_output"),
        "metadata": row
    }
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";

async function evaluateDataset(datasetKey: string, version?: string) {
    const dataset = traceloop.getDataset(datasetKey, version);
    const results = [];
    
    // Process in parallel for better performance
    const promises = dataset.map(async (row) => {
        const inputData = row.input;
        const result = await yourAiFunction(inputData);
        
        return {
            input: inputData,
            output: result,
            expected: row.expected_output,
            metadata: row
        };
    });
    
    const results = await Promise.all(promises);
    return results;
}
```

</CodeGroup>

<Warning>  
  When processing datasets in parallel, be mindful of rate limits on your
  AI provider's API. Consider implementing appropriate throttling or using
  a smaller number of concurrent workers.
</Warning>

## Real-World Integration Examples

### Customer Support Dataset with OpenAI

Create datasets with AI-generated responses for testing customer support scenarios:

<CodeGroup>

```python Python
import openai
import pandas as pd
from datetime import datetime
from traceloop.sdk import Traceloop

client = Traceloop.init()

def create_customer_support_dataset():
    queries = [
        "How do I reset my password?",
        "My order hasn't arrived yet, what should I do?", 
        "Can I return this item after 30 days?",
        "Do you offer international shipping?",
        "What's your refund policy?"
    ]
    
    data = []
    openai_client = openai.OpenAI()
    
    for query in queries:
        try:
            response = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful customer support agent."},
                    {"role": "user", "content": query}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            
            data.append({
                "customer_query": query,
                "ai_response": ai_response,
                "timestamp": datetime.now().isoformat(),
                "category": "general_support",
                "resolved": True
            })
            
        except Exception as e:
            print(f"Error generating response: {e}")
            data.append({
                "customer_query": query,
                "ai_response": "Error generating response",
                "timestamp": datetime.now().isoformat(),
                "category": "general_support", 
                "resolved": False
            })
    
    df = pd.DataFrame(data)
    
    dataset = client.datasets.from_dataframe(
        df=df,
        slug="customer-support-interactions",
        name="Customer Support Interactions",
        description="Customer queries with AI-generated support responses"
    )
    
    return dataset

# Create and publish the dataset
support_dataset = create_customer_support_dataset()
version = support_dataset.publish()
print(f"Published customer support dataset version: {version}")
```

```js Typescript / Javascript
import * as traceloop from "@traceloop/node-server-sdk";
import OpenAI from "openai";

const client = traceloop.getClient();

async function createLLMInteractionsDataset() {
  // Create dataset
  const dataset = await client.datasets.create({
    name: `llm-interactions-${Date.now()}`,
    description: "Dataset for tracking OpenAI chat completions and user interactions"
  });

  // Define schema
  const columnsToAdd = [
    {
      name: "user_id",
      type: "string" as const,
      required: true,
      description: "Unique identifier for the user"
    },
    {
      name: "prompt",
      type: "string" as const,
      required: true,
      description: "The user's input prompt"
    },
    {
      name: "response",
      type: "string" as const,
      required: true,
      description: "The AI model's response"
    },
    {
      name: "model",
      type: "string" as const,
      required: true,
      description: "The AI model used"
    },
    {
      name: "tokens_used",
      type: "number" as const,
      required: false,
      description: "Total tokens consumed"
    },
    {
      name: "response_time_ms",
      type: "number" as const,
      required: false,
      description: "Response time in milliseconds"
    },
    {
      name: "satisfaction_score",
      type: "number" as const,
      required: false,
      description: "User satisfaction rating (1-5)"
    },
    {
      name: "timestamp",
      type: "string" as const,
      required: true,
      description: "When the interaction occurred"
    }
  ];
  
  await dataset.addColumn(columnsToAdd);

  // Generate data with OpenAI
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  const samplePrompts = [
    "Explain machine learning in simple terms",
    "Write a Python function to calculate fibonacci numbers",
    "What are the benefits of using TypeScript?",
    "How does async/await work in JavaScript?",
    "Explain the concept of closures in programming"
  ];

  for (let i = 0; i < samplePrompts.length; i++) {
    const prompt = samplePrompts[i];
    const userId = `user_${String(i + 1).padStart(3, "0")}`;
    const startTime = Date.now();

    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [{ role: "user", content: prompt }],
        max_tokens: 150
      });

      const endTime = Date.now();
      const response = completion.choices[0]?.message?.content || "No response";
      const tokensUsed = completion.usage?.total_tokens || 0;
      const responseTime = endTime - startTime;

      const interaction = {
        user_id: userId,
        prompt: prompt,
        response: response,
        model: "gpt-3.5-turbo",
        tokens_used: tokensUsed,
        response_time_ms: responseTime,
        satisfaction_score: Math.floor(Math.random() * 5) + 1,
        timestamp: new Date().toISOString()
      };

      await dataset.addRow(interaction);
      console.log(`Added interaction for prompt ${i + 1}`);
      
    } catch (error) {
      console.log(`Error with prompt ${i + 1}: ${error.message}`);
      
      const errorInteraction = {
        user_id: userId,
        prompt: prompt,
        response: `Error: ${error.message}`,
        model: "gpt-3.5-turbo",
        tokens_used: 0,
        response_time_ms: Date.now() - startTime,
        satisfaction_score: 1,
        timestamp: new Date().toISOString()
      };

      await dataset.addRow(errorInteraction);
    }
  }

  // Publish the dataset
  await dataset.publish({
    version: "v1.0",
    description: "Initial release of LLM interactions dataset with sample data"
  });

  console.log(`Dataset published: ${dataset.name}`);
  return dataset;
}

// Create and publish the dataset
const interactionsDataset = await createLLMInteractionsDataset();
```

</CodeGroup>

### Translation Dataset

Generate translation datasets for multilingual testing:

<CodeGroup>

```python Python
import openai
import pandas as pd
from datetime import datetime
from traceloop.sdk import Traceloop

client = Traceloop.init()

def create_translation_dataset():
    phrases = [
        "Hello, how are you today?",
        "Thank you for your help.",
        "Where is the nearest restaurant?",
        "I would like to book a room.",
        "What time does the store close?"
    ]
    
    languages = ["Spanish", "French", "German", "Italian"]
    data = []
    openai_client = openai.OpenAI()
    
    for phrase in phrases:
        for lang in languages:
            try:
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": f"Translate to {lang}. Provide only the translation."},
                        {"role": "user", "content": phrase}
                    ],
                    max_tokens=100,
                    temperature=0.3
                )
                
                translation = response.choices[0].message.content.strip()
                
                data.append({
                    "source_text": phrase,
                    "target_language": lang,
                    "translation": translation,
                    "timestamp": datetime.now().isoformat(),
                    "confidence_score": 0.95
                })
                
            except Exception as e:
                print(f"Translation error: {e}")
                data.append({
                    "source_text": phrase,
                    "target_language": lang,
                    "translation": f"[Translation error for {lang}]",
                    "timestamp": datetime.now().isoformat(),
                    "confidence_score": 0.0
                })
    
    df = pd.DataFrame(data)
    
    dataset = client.datasets.from_dataframe(
        df=df,
        slug="translation-results",
        name="Translation Results",
        description="Text translations generated using AI"
    )
    
    return dataset

# Create and publish the dataset
translation_dataset = create_translation_dataset()
version = translation_dataset.publish()
print(f"Published translation dataset version: {version}")
```

</CodeGroup>

### Dataset Cleanup

<CodeGroup>

```python Python
# Delete datasets when no longer needed
def cleanup_datasets():
    # Delete by slug
    client.datasets.delete_by_slug("customer-support-interactions")
    client.datasets.delete_by_slug("translation-results") 
    print("Datasets cleaned up")

# Call when needed
cleanup_datasets()
```

</CodeGroup>

<Tip>
  These examples show how to integrate datasets with AI providers like OpenAI
  to create rich test data. You can adapt these patterns for your specific
  use cases and AI models.
</Tip>